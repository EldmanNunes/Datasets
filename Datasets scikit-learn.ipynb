{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNoJrRm6xxRE4bYytOSZsFb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**Objetivo:** listar exemplos de conjuntos de dados disponíveis no módulo datasets do scikit-learn, divididos por problemas de classificação, regressão, agrupamento e associação.\n","\n","Estes são exemplos adicionais de conjuntos de dados disponíveis no scikit-learn para diferentes tipos de problemas de aprendizado de máquina. Cada conjunto de dados tem uma finalidade específica e pode ser usado para testar e praticar algoritmos em diferentes contextos."],"metadata":{"id":"WrQ7pEDdHkOI"}},{"cell_type":"code","source":["#!pip install scikit-learn\n","#!pip install --upgrade scikit-learn"],"metadata":{"id":"sFyjZWTLLeVC","executionInfo":{"status":"ok","timestamp":1712601123174,"user_tz":180,"elapsed":6,"user":{"displayName":"Eldman Nunes","userId":"03493753706215259317"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["1. **Classificação**:\n","\n","* **Iris Dataset (load_iris)**: Um conjunto de dados de medidas de pétalas e sépalas de três espécies de íris, com 150 amostras. O objetivo é classificar as amostras em das três classes.\n","\n","* **Wine Dataset (load_wine)**: Um conjunto de dados de análise química de vinhos, com 178 amostras e 13 características. O objetivo é classificar os vinhos em uma das três classes.\n","\n","* **Breast Cancer Wisconsin (Diagnostic) Dataset (load_breast_cancer)**: Um conjunto de dados de diagnóstico de câncer de mama, com 569 amostras e 30 características clínicas. O objetivo é prever se um tumor é benigno ou maligno.\n","\n","* **Titanic Dataset (fetch_openml(name='titanic'))**: Um conjunto de dados com informações sobre passageiros do Titanic, como idade, sexo, classe social, etc. O objetivo é prever se um passageiro sobreviveu ao desastre.\n","\n","* **Census Income Dataset**: Este conjunto de dados contém informações sobre adultos dos EUA, coletadas a partir do censo de 1994. Ele inclui características como idade, educação, ocupação, estado civil, entre outras. O objetivo é prever se a renda de um adulto excede 50,000 dólares por ano com base em suas características demográficas e socioeconômicas (Classificação binária: renda superior a $50,000 ou não).\n","\n","* **Bank Marketing Dataset (fetch_openml(name='bank-marketing'))**: Este conjunto de dados contém informações relacionadas a campanhas de marketing direto de uma instituição bancária portuguesa. Inclui atributos como idade, ocupação, estado civil, educação, entre outros, e o objetivo é prever se um cliente subscreverá (ou não) um produto bancário (depósito a prazo).\n","\n","* **MNIST Dataset (load_digits)**: Um conjunto de dados de dígitos escritos à mão, com 70.000 imagens em escala de cinza de 8x8 pixels. Cada imagem é um dígito de 0 a 9.\n","\n","* **CIFAR-10 Dataset (fetch_openml(name='CIFAR_10'))**: Um conjunto de dados de imagens coloridas de 32x32 pixels, com 10 classes diferentes, como aviões, carros e pássaros."],"metadata":{"id":"Xs_64tYaZKp3"}},{"cell_type":"code","source":["# Problemas de Classificação\n","# Importar biblioteca para carregar conjuntos de dados\n","from sklearn.datasets import load_iris, load_breast_cancer, load_wine\n","from sklearn.datasets import fetch_openml\n","\n","# Carregar conjuntos de dados para problemas de classificação\n","iris = load_iris()\n","wine = load_wine()\n","breast_cancer = load_breast_cancer()\n","titanic = fetch_openml(name='titanic')\n","census_income = fetch_openml(name='census-income')\n","bank_marketing = fetch_openml(name='bank-marketing')\n","# Conjunto contendo imagens - um pouco pesado\n","# mnist = load_digits()\n","# cifar_10 = fetch_openml(name='CIFAR_10')"],"metadata":{"id":"LFc6qozfLLrF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712601261040,"user_tz":180,"elapsed":137870,"user":{"displayName":"Eldman Nunes","userId":"03493753706215259317"}},"outputId":"ac565d1d-ba10-44e9-ec09-03b5f40fd17f"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:301: UserWarning: Multiple active versions of the dataset matching the name titanic exist. Versions may be fundamentally different, returning version 2.\n","  warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n","  warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n","  warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:301: UserWarning: Multiple active versions of the dataset matching the name bank-marketing exist. Versions may be fundamentally different, returning version 1.\n","  warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n","  warn(\n"]}]},{"cell_type":"code","source":["# Visualizar informações sobre os conjuntos de dados de classificação\n","print(\"Conjunto de dados Iris:\")\n","print(iris.DESCR)\n","\n","print(\"\\nConjunto de dados Wine:\")\n","print(wine.DESCR)\n","\n","print(\"\\nConjunto de dados Breast Cancer:\")\n","print(breast_cancer.DESCR)\n","\n","print(\"\\nConjunto de dados Titanic:\")\n","print(titanic.DESCR)\n","\n","print(\"\\nConjunto de dados Census Income:\")\n","print(census_income.DESCR)\n","\n","print(\"\\nConjunto de dados Bank Marketing:\")\n","print(bank_marketing.DESCR)"],"metadata":{"id":"hzNOsJdmBjhh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Para obter informações do Dataset\n","\n","# Carregar o conjunto de dados Titanic\n","titanic = fetch_openml(name='titanic')\n","\n","# Número de amostras (registros)\n","num_samples = titanic.data.shape[0]\n","\n","# Número de características (colunas)\n","num_features = titanic.data.shape[1]\n","\n","# Nomes das características\n","feature_names = titanic.feature_names\n","\n","# Descrição do conjunto de dados\n","dataset_description = titanic.DESCR\n","\n","# Imprimir informações\n","print(\"Informações sobre o conjunto de dados Titanic:\")\n","print(\"Número de amostras (registros):\", num_samples)\n","print(\"Número de características (colunas):\", num_features)\n","print(\"Nomes das características:\", feature_names)\n","print(\"Descrição do conjunto de dados:\")\n","print(dataset_description)"],"metadata":{"id":"ZXhSdtf8k_51","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712601409405,"user_tz":180,"elapsed":521,"user":{"displayName":"Eldman Nunes","userId":"03493753706215259317"}},"outputId":"b4139945-e8f4-44b5-cce9-55ef91e0e804"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Informações sobre o conjunto de dados Titanic:\n","Número de amostras (registros): 2201\n","Número de características (colunas): 3\n","Nomes das características: ['Class', 'Age', 'Sex']\n","Descrição do conjunto de dados:\n","PMLB version of the Titanic dataset, which only uses 3 features. See version 1 for the complete version: https://www.openml.org/d/40945\n","\n","Downloaded from openml.org.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:301: UserWarning: Multiple active versions of the dataset matching the name titanic exist. Versions may be fundamentally different, returning version 2.\n","  warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n","  warn(\n"]}]},{"cell_type":"markdown","source":["2. **Regressão**:\n","* **Diabetes Dataset (load_diabetes)**: Um conjunto de dados de diagnóstico de diabetes, com 442 amostras e 10 características clínicas. O objetivo é prever a progressão da doença após um ano.\n","\n","* **California Housing Dataset (fetch_california_housing)**: Um conjunto de dados de preços de habitação na Califórnia, com 20.640 amostras e 8 características geográficas. O objetivo é prever o valor médio das casas em um bairro.\n","\n","* **Energy Efficiency Dataset**: Este conjunto de dados contém informações sobre a eficiência energética de edifícios. Ele inclui o desempenho térmico de diferentes edifícios, bem como características relacionadas ao projeto, como área de superfície, orientação, altura, entre outras. O Objetivo é prever a eficiência energética de um edifício com base em suas características de projeto.\n"],"metadata":{"id":"Vp_TcR3XZd9e"}},{"cell_type":"code","source":["# Problemas de Regressão\n","# Importar biblioteca para carregar conjuntos de dados\n","from sklearn.datasets import load_diabetes, fetch_california_housing\n","from sklearn.datasets import fetch_openml\n","\n","# Carregar conjuntos de dados para problemas de regressão\n","diabetes = load_diabetes()\n","california_housing = fetch_california_housing()\n","energy_efficiency = fetch_openml(name='energy_efficiency')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FWL-bKzaAMbO","executionInfo":{"status":"ok","timestamp":1712601488531,"user_tz":180,"elapsed":3674,"user":{"displayName":"Eldman Nunes","userId":"03493753706215259317"}},"outputId":"0c32705d-063e-44a3-8149-ba06926beb71"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:301: UserWarning: Multiple active versions of the dataset matching the name energy_efficiency exist. Versions may be fundamentally different, returning version 1.\n","  warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n","  warn(\n"]}]},{"cell_type":"code","source":["# Visualizar informações sobre os conjuntos de dados de regressão\n","print(\"\\nConjunto de dados Diabetes:\")\n","print(diabetes.DESCR)\n","\n","print(\"\\nConjunto de dados California Housing:\")\n","print(california_housing.DESCR)\n","\n","print(\"\\nConjunto de dados Energy Efficiency:\")\n","print(\"Número de atributos:\", energy_efficiency.data.shape[1])\n","print(\"Número de objetos:\", energy_efficiency.data.shape[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"or-D8jGPBwpK","executionInfo":{"status":"ok","timestamp":1712601896678,"user_tz":180,"elapsed":292,"user":{"displayName":"Eldman Nunes","userId":"03493753706215259317"}},"outputId":"9f37bebb-5722-4ecf-ed3c-8ba8b7d76b28"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Conjunto de dados Diabetes:\n",".. _diabetes_dataset:\n","\n","Diabetes dataset\n","----------------\n","\n","Ten baseline variables, age, sex, body mass index, average blood\n","pressure, and six blood serum measurements were obtained for each of n =\n","442 diabetes patients, as well as the response of interest, a\n","quantitative measure of disease progression one year after baseline.\n","\n","**Data Set Characteristics:**\n","\n","  :Number of Instances: 442\n","\n","  :Number of Attributes: First 10 columns are numeric predictive values\n","\n","  :Target: Column 11 is a quantitative measure of disease progression one year after baseline\n","\n","  :Attribute Information:\n","      - age     age in years\n","      - sex\n","      - bmi     body mass index\n","      - bp      average blood pressure\n","      - s1      tc, total serum cholesterol\n","      - s2      ldl, low-density lipoproteins\n","      - s3      hdl, high-density lipoproteins\n","      - s4      tch, total cholesterol / HDL\n","      - s5      ltg, possibly log of serum triglycerides level\n","      - s6      glu, blood sugar level\n","\n","Note: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times the square root of `n_samples` (i.e. the sum of squares of each column totals 1).\n","\n","Source URL:\n","https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\n","\n","For more information see:\n","Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\n","(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)\n","\n","\n","Conjunto de dados California Housing:\n",".. _california_housing_dataset:\n","\n","California Housing dataset\n","--------------------------\n","\n","**Data Set Characteristics:**\n","\n","    :Number of Instances: 20640\n","\n","    :Number of Attributes: 8 numeric, predictive attributes and the target\n","\n","    :Attribute Information:\n","        - MedInc        median income in block group\n","        - HouseAge      median house age in block group\n","        - AveRooms      average number of rooms per household\n","        - AveBedrms     average number of bedrooms per household\n","        - Population    block group population\n","        - AveOccup      average number of household members\n","        - Latitude      block group latitude\n","        - Longitude     block group longitude\n","\n","    :Missing Attribute Values: None\n","\n","This dataset was obtained from the StatLib repository.\n","https://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html\n","\n","The target variable is the median house value for California districts,\n","expressed in hundreds of thousands of dollars ($100,000).\n","\n","This dataset was derived from the 1990 U.S. census, using one row per census\n","block group. A block group is the smallest geographical unit for which the U.S.\n","Census Bureau publishes sample data (a block group typically has a population\n","of 600 to 3,000 people).\n","\n","A household is a group of people residing within a home. Since the average\n","number of rooms and bedrooms in this dataset are provided per household, these\n","columns may take surprisingly large values for block groups with few households\n","and many empty houses, such as vacation resorts.\n","\n","It can be downloaded/loaded using the\n",":func:`sklearn.datasets.fetch_california_housing` function.\n","\n",".. topic:: References\n","\n","    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n","      Statistics and Probability Letters, 33 (1997) 291-297\n","\n","\n","Conjunto de dados Energy Efficiency:\n","Número de atributos: 8\n","Número de objetos: 768\n"]}]},{"cell_type":"markdown","source":["**3. Agrupamento:**\n","\n","* **Iris Dataset (load_iris)**: Um conjunto de dados de medidas de pétalas e sépalas de três espécies de íris, com 150 amostras. O objetivo é agrupar as amostras em clusters semelhantes.\n","\n","* **Wine Dataset (load_wine)**: Um conjunto de dados de análise química de vinhos, com 178 amostras e 13 características. O objetivo é agrupar as amostras em clusters semelhantes."],"metadata":{"id":"e3Zn65O0ZpuW"}},{"cell_type":"code","source":["# Problemas de Agrupamento\n","# Importar biblioteca para carregar conjuntos de dados\n","from sklearn.datasets import load_iris\n","from sklearn.datasets import fetch_openml\n","\n","# Carregar conjuntos de dados para problemas de agrupamento\n","iris = load_iris()\n","wine = load_wine()"],"metadata":{"id":"hA7-TUbTLTW-","executionInfo":{"status":"aborted","timestamp":1712601261043,"user_tz":180,"elapsed":16,"user":{"displayName":"Eldman Nunes","userId":"03493753706215259317"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**4. Associação:**\n","* **Market Basket Dataset**: Este conjunto de dados contém informações sobre transações de compras em um supermercado, onde cada linha representa uma transação e os itens comprados nessa transação.\n","\n","Como o Market Basket Dataset não está disponível diretamente na biblioteca Scikit-learn ou no repositório OpenML, você precisará obter o conjunto de dados de uma fonte alternativa. Aqui está um exemplo de código que mostra como carregar o conjunto de dados a partir de um arquivo CSV usando a biblioteca pandas:\n"],"metadata":{"id":"2jo6xv4maAVD"}},{"cell_type":"code","source":["import pandas as pd\n","\n","# Carregar o conjunto de dados Market Basket a partir de um arquivo CSV\n","market_basket_data = pd.read_csv('caminho/do/seu/arquivo/market_basket_dataset.csv')\n","\n","# Visualizar as primeiras linhas do conjunto de dados\n","print(market_basket_data.head())"],"metadata":{"id":"XeKgkg1OiVsD","colab":{"base_uri":"https://localhost:8080/","height":390},"executionInfo":{"status":"error","timestamp":1712601930366,"user_tz":180,"elapsed":313,"user":{"displayName":"Eldman Nunes","userId":"03493753706215259317"}},"outputId":"1d08a0a8-8740-4510-9688-a3d875b31372"},"execution_count":15,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'caminho/do/seu/arquivo/market_basket_dataset.csv'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-7fcdec7ba691>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Carregar o conjunto de dados Market Basket a partir de um arquivo CSV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmarket_basket_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'caminho/do/seu/arquivo/market_basket_dataset.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Visualizar as primeiras linhas do conjunto de dados\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    910\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1661\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1662\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1663\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'caminho/do/seu/arquivo/market_basket_dataset.csv'"]}]},{"cell_type":"markdown","source":["**Repositório OpenML**\n","\n","Você pode acessar o repositório OpenML diretamente pelo site oficial em https://www.openml.org/. Neste site, você pode explorar uma ampla variedade de conjuntos de dados, experimentos e modelos de aprendizado de máquina compartilhados pela comunidade.\n","\n","Além disso, você também pode acessar o repositório OpenML diretamente pela API do Python, que é fornecida pela biblioteca openml. Aqui está um exemplo simples de como usar a API para listar todos os conjuntos de dados disponíveis:"],"metadata":{"id":"0iTUPr3IUv7w"}},{"cell_type":"code","source":["!pip install openml\n","import openml\n","\n","# Listar todos os conjuntos de dados disponíveis\n","datasets = openml.datasets.list_datasets()\n","\n","# Imprimir os primeiros 10 conjuntos de dados\n","for dataset_id, dataset in list(datasets.items())[:10]:\n","    default_target_attribute = dataset.get('default_target_attribute', 'N/A')\n","    print(f\"ID: {dataset_id}, Nome: {dataset['name']}, Tarefa: {default_target_attribute}\")"],"metadata":{"id":"sbiingb6Usfh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712601973906,"user_tz":180,"elapsed":33868,"user":{"displayName":"Eldman Nunes","userId":"03493753706215259317"}},"outputId":"bd096c19-ae0e-4d36-9985-b2a8093eabad"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting openml\n","  Downloading openml-0.14.2.tar.gz (144 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/144.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m143.4/144.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.5/144.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting liac-arff>=2.4.0 (from openml)\n","  Downloading liac-arff-2.5.0.tar.gz (13 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting xmltodict (from openml)\n","  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from openml) (2.31.0)\n","Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.10/dist-packages (from openml) (1.2.2)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from openml) (2.8.2)\n","Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from openml) (2.0.3)\n","Requirement already satisfied: scipy>=0.13.3 in /usr/local/lib/python3.10/dist-packages (from openml) (1.11.4)\n","Requirement already satisfied: numpy>=1.6.2 in /usr/local/lib/python3.10/dist-packages (from openml) (1.25.2)\n","Collecting minio (from openml)\n","  Downloading minio-7.2.5-py3-none-any.whl (93 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.2/93.2 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (from openml) (14.0.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->openml) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->openml) (2024.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil->openml) (1.16.0)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->openml) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->openml) (3.4.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from minio->openml) (2024.2.2)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from minio->openml) (2.0.7)\n","Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from minio->openml) (23.1.0)\n","Collecting pycryptodome (from minio->openml)\n","  Downloading pycryptodome-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from minio->openml) (4.10.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->openml) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->openml) (3.6)\n","Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->minio->openml) (21.2.0)\n","Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->minio->openml) (1.16.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->minio->openml) (2.22)\n","Building wheels for collected packages: openml, liac-arff\n","  Building wheel for openml (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for openml: filename=openml-0.14.2-py3-none-any.whl size=158699 sha256=2bf2f035665dce0c6eaa7010fb65db10ef83702015249311d33a19ed0040eded\n","  Stored in directory: /root/.cache/pip/wheels/2e/4e/af/5e721761d86375dbca82e63cc2470019e97815bc39f11451ea\n","  Building wheel for liac-arff (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for liac-arff: filename=liac_arff-2.5.0-py3-none-any.whl size=11716 sha256=4417eb37218a64920185de09dbfaae65ce549162ff88919a1be18bdb28a894ca\n","  Stored in directory: /root/.cache/pip/wheels/5d/2a/9c/3895d9617f8f49a0883ba686326d598e78a1c2f54fe3cae86d\n","Successfully built openml liac-arff\n","Installing collected packages: xmltodict, pycryptodome, liac-arff, minio, openml\n","Successfully installed liac-arff-2.5.0 minio-7.2.5 openml-0.14.2 pycryptodome-3.20.0 xmltodict-0.13.0\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:openml:No permission to create OpenML directory at /root/.config/openml! This can result in OpenML-Python not working properly.\n","<ipython-input-16-035129b8bddb>:5: FutureWarning: Support for `output_format` of 'dict' will be removed in 0.15 and pandas dataframes will be returned instead. To ensure your code will continue to work, use `output_format`='dataframe'.\n","  datasets = openml.datasets.list_datasets()\n"]},{"output_type":"stream","name":"stdout","text":["ID: 2, Nome: anneal, Tarefa: N/A\n","ID: 3, Nome: kr-vs-kp, Tarefa: N/A\n","ID: 4, Nome: labor, Tarefa: N/A\n","ID: 5, Nome: arrhythmia, Tarefa: N/A\n","ID: 6, Nome: letter, Tarefa: N/A\n","ID: 7, Nome: audiology, Tarefa: N/A\n","ID: 8, Nome: liver-disorders, Tarefa: N/A\n","ID: 9, Nome: autos, Tarefa: N/A\n","ID: 10, Nome: lymph, Tarefa: N/A\n","ID: 11, Nome: balance-scale, Tarefa: N/A\n"]}]},{"cell_type":"markdown","source":["Para importar um conjunto de dados específico do repositório OpenML e obter informações sobre ele, você pode usar a função openml.datasets.get_dataset() e fornecer o ID do conjunto de dados que você deseja importar. Em seguida, você pode usar os métodos e atributos do objeto Dataset retornado para obter informações sobre o conjunto de dados."],"metadata":{"id":"1ECksgnOVpCn"}},{"cell_type":"code","source":["import openml\n","# Importar o conjunto de dados com o ID específico (por exemplo, ID 5: arrhythmia)\n","dataset_id = 5\n","dataset = openml.datasets.get_dataset(dataset_id)\n","\n","# Imprimir informações sobre o conjunto de dados\n","print(\"Nome do conjunto de dados:\", dataset.name)\n","print(\"----------------------------------------\")\n","print(\"Descrição do conjunto de dados:\", dataset.description)\n","print(\"----------------------------------------\")\n","print(\"Atributos do conjunto de dados:\", dataset.features)\n","print(\"----------------------------------------\")\n","print(\"Rótulo padrão do conjunto de dados:\", dataset.default_target_attribute)"],"metadata":{"id":"M1Of8Ji1VtTm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712601977685,"user_tz":180,"elapsed":3784,"user":{"displayName":"Eldman Nunes","userId":"03493753706215259317"}},"outputId":"6b68cec6-692b-4a81-ff28-c1193051fb32"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-17-0f217e1e2613>:4: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n","  dataset = openml.datasets.get_dataset(dataset_id)\n"]},{"output_type":"stream","name":"stdout","text":["Nome do conjunto de dados: arrhythmia\n","----------------------------------------\n","Descrição do conjunto de dados: **Author**: H. Altay Guvenir, Burak Acar, Haldun Muderrisoglu  \n","**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/arrhythmia)   \n","**Please cite**: [UCI](https://archive.ics.uci.edu/ml/citation_policy.html)\n","\n","**Cardiac Arrhythmia Database**  \n","The aim is to determine the type of arrhythmia from the ECG recordings. This database contains 279 attributes, 206 of which are linear valued and the rest are nominal. \n","\n","Concerning the study of H. Altay Guvenir: \"The aim is to distinguish between the presence and absence of cardiac arrhythmia and to classify it in one of the 16 groups. Class 01 refers to 'normal' ECG classes, 02 to 15 refers to different classes of arrhythmia and class 16 refers to the rest of unclassified ones. For the time being, there exists a computer program that makes such a classification. However, there are differences between the cardiologist's and the program's classification. Taking the cardiologist's as a gold standard we aim to minimize this difference by means of machine learning tools.\n"," \n","The names and id numbers of the patients were recently removed from the database.\n"," \n","### Attribute Information  \n"," \n","       1 Age: Age in years , linear\n","       2 Sex: Sex (0 = male; 1 = female) , nominal\n","       3 Height: Height in centimeters , linear\n","       4 Weight: Weight in kilograms , linear\n","       5 QRS duration: Average of QRS duration in msec., linear\n","       6 P-R interval: Average duration between onset of P and Q waves\n","         in msec., linear\n","       7 Q-T interval: Average duration between onset of Q and offset\n","         of T waves in msec., linear\n","       8 T interval: Average duration of T wave in msec., linear\n","       9 P interval: Average duration of P wave in msec., linear\n","      Vector angles in degrees on front plane of:, linear\n","      10 QRS\n","      11 T\n","      12 P\n","      13 QRST\n","      14 J\n","      15 Heart rate: Number of heart beats per minute ,linear\n","      Of channel DI:\n","       Average width, in msec., of: linear\n","       16 Q wave\n","       17 R wave\n","       18 S wave\n","       19 R' wave, small peak just after R\n","       20 S' wave\n","       21 Number of intrinsic deflections, linear\n","       22 Existence of ragged R wave, nominal\n","       23 Existence of diphasic derivation of R wave, nominal\n","       24 Existence of ragged P wave, nominal\n","       25 Existence of diphasic derivation of P wave, nominal\n","       26 Existence of ragged T wave, nominal\n","       27 Existence of diphasic derivation of T wave, nominal\n","      Of channel DII: \n","       28 .. 39 (similar to 16 .. 27 of channel DI)\n","      Of channels DIII:\n","       40 .. 51\n","      Of channel AVR:\n","       52 .. 63\n","      Of channel AVL:\n","       64 .. 75\n","      Of channel AVF:\n","       76 .. 87\n","      Of channel V1:\n","       88 .. 99\n","      Of channel V2:\n","       100 .. 111\n","      Of channel V3:\n","       112 .. 123\n","      Of channel V4:\n","       124 .. 135\n","      Of channel V5:\n","       136 .. 147\n","      Of channel V6:\n","       148 .. 159\n","      Of channel DI:\n","       Amplitude , * 0.1 milivolt, of\n","       160 JJ wave, linear\n","       161 Q wave, linear\n","       162 R wave, linear\n","       163 S wave, linear\n","       164 R' wave, linear\n","       165 S' wave, linear\n","       166 P wave, linear\n","       167 T wave, linear\n","       168 QRSA , Sum of areas of all segments divided by 10,\n","           ( Area= width * height / 2 ), linear\n","       169 QRSTA = QRSA + 0.5 * width of T wave * 0.1 * height of T\n","           wave. (If T is diphasic then the bigger segment is\n","           considered), linear\n","      Of channel DII:\n","       170 .. 179\n","      Of channel DIII:\n","       180 .. 189\n","      Of channel AVR:\n","       190 .. 199\n","      Of channel AVL:\n","       200 .. 209\n","      Of channel AVF:\n","       210 .. 219\n","      Of channel V1:\n","       220 .. 229\n","      Of channel V2:\n","       230 .. 239\n","      Of channel V3:\n","       240 .. 249\n","      Of channel V4:\n","       250 .. 259\n","      Of channel V5:\n","       260 .. 269\n","      Of channel V6:\n","       270 .. 279\n","        \n","Class code - class - number of instances:\n","> \n","        01             Normal                245\n","        02             Ischemic changes (Coronary Artery Disease)   44\n","        03             Old Anterior Myocardial Infarction           15\n","        04             Old Inferior Myocardial Infarction           15\n","        05             Sinus tachycardy        13\n","        06             Sinus bradycardy        25\n","        07             Ventricular Premature Contraction (PVC)       3\n","        08             Supraventricular Premature Contraction       2\n","        09             Left bundle branch block         9 \n","        10             Right bundle branch block       50\n","        11             1. degree AtrioVentricular block       0 \n","        12             2. degree AV block                0\n","        13             3. degree AV block                0\n","        14             Left ventricule hypertrophy                4\n","        15             Atrial Fibrillation or Flutter               5\n","        16             Others                 22\n","----------------------------------------\n","Atributos do conjunto de dados: {0: [0 - age (numeric)], 1: [1 - sex (nominal)], 2: [2 - height (numeric)], 3: [3 - weight (numeric)], 4: [4 - QRSduration (numeric)], 5: [5 - PRinterval (numeric)], 6: [6 - Q-Tinterval (numeric)], 7: [7 - Tinterval (numeric)], 8: [8 - Pinterval (numeric)], 9: [9 - QRS (numeric)], 10: [10 - T (numeric)], 11: [11 - P (numeric)], 12: [12 - QRST (numeric)], 13: [13 - J (numeric)], 14: [14 - heartrate (numeric)], 15: [15 - chDI_Qwave (numeric)], 16: [16 - chDI_Rwave (numeric)], 17: [17 - chDI_Swave (numeric)], 18: [18 - chDI_RPwave (numeric)], 19: [19 - chDI_SPwave (numeric)], 20: [20 - chDI_intrinsicReflecttions (numeric)], 21: [21 - chDI_RRwaveExists (nominal)], 22: [22 - chDI_DD_RRwaveExists (nominal)], 23: [23 - chDI_RPwaveExists (nominal)], 24: [24 - chDI_DD_RPwaveExists (nominal)], 25: [25 - chDI_RTwaveExists (nominal)], 26: [26 - chDI_DD_RTwaveExists (nominal)], 27: [27 - chDII_Qwave (numeric)], 28: [28 - chDII_Rwave (numeric)], 29: [29 - chDII_Swave (numeric)], 30: [30 - chDII_RPwave (numeric)], 31: [31 - chDII_SPwave (numeric)], 32: [32 - chDII_intrinsicReflecttions (numeric)], 33: [33 - chDII_RRwaveExists (nominal)], 34: [34 - chDII_DD_RRwaveExists (nominal)], 35: [35 - chDII_RPwaveExists (nominal)], 36: [36 - chDII_DD_RPwaveExists (nominal)], 37: [37 - chDII_RTwaveExists (nominal)], 38: [38 - chDII_DD_RTwaveExists (nominal)], 39: [39 - chDIII_Qwave (numeric)], 40: [40 - chDIII_Rwave (numeric)], 41: [41 - chDIII_Swave (numeric)], 42: [42 - chDIII_RPwave (numeric)], 43: [43 - chDIII_SPwave (numeric)], 44: [44 - chDIII_intrinsicReflecttions (numeric)], 45: [45 - chDIII_RRwaveExists (nominal)], 46: [46 - chDIII_DD_RRwaveExists (nominal)], 47: [47 - chDIII_RPwaveExists (nominal)], 48: [48 - chDIII_DD_RPwaveExists (nominal)], 49: [49 - chDIII_RTwaveExists (nominal)], 50: [50 - chDIII_DD_RTwaveExists (nominal)], 51: [51 - chAVR_Qwave (numeric)], 52: [52 - chAVR_Rwave (numeric)], 53: [53 - chAVR_Swave (numeric)], 54: [54 - chAVR_RPwave (numeric)], 55: [55 - chAVR_SPwave (numeric)], 56: [56 - chAVR_intrinsicReflecttions (numeric)], 57: [57 - chAVR_RRwaveExists (nominal)], 58: [58 - chAVR_DD_RRwaveExists (nominal)], 59: [59 - chAVR_RPwaveExists (nominal)], 60: [60 - chAVR_DD_RPwaveExists (nominal)], 61: [61 - chAVR_RTwaveExists (nominal)], 62: [62 - chAVR_DD_RTwaveExists (nominal)], 63: [63 - chAVL_Qwave (numeric)], 64: [64 - chAVL_Rwave (numeric)], 65: [65 - chAVL_Swave (numeric)], 66: [66 - chAVL_RPwave (numeric)], 67: [67 - chAVL_SPwave (numeric)], 68: [68 - chAVL_intrinsicReflecttions (numeric)], 69: [69 - chAVL_RRwaveExists (nominal)], 70: [70 - chAVL_DD_RRwaveExists (nominal)], 71: [71 - chAVL_RPwaveExists (nominal)], 72: [72 - chAVL_DD_RPwaveExists (nominal)], 73: [73 - chAVL_RTwaveExists (nominal)], 74: [74 - chAVL_DD_RTwaveExists (nominal)], 75: [75 - chAVF_Qwave (numeric)], 76: [76 - chAVF_Rwave (numeric)], 77: [77 - chAVF_Swave (numeric)], 78: [78 - chAVF_RPwave (numeric)], 79: [79 - chAVF_SPwave (numeric)], 80: [80 - chAVF_intrinsicReflecttions (numeric)], 81: [81 - chAVF_RRwaveExists (nominal)], 82: [82 - chAVF_DD_RRwaveExists (nominal)], 83: [83 - chAVF_RPwaveExists (nominal)], 84: [84 - chAVF_DD_RPwaveExists (nominal)], 85: [85 - chAVF_RTwaveExists (nominal)], 86: [86 - chAVF_DD_RTwaveExists (nominal)], 87: [87 - chV1_Qwave (numeric)], 88: [88 - chV1_Rwave (numeric)], 89: [89 - chV1_Swave (numeric)], 90: [90 - chV1_RPwave (numeric)], 91: [91 - chV1_SPwave (numeric)], 92: [92 - chV1_intrinsicReflecttions (numeric)], 93: [93 - chV1_RRwaveExists (nominal)], 94: [94 - chV1_DD_RRwaveExists (nominal)], 95: [95 - chV1_RPwaveExists (nominal)], 96: [96 - chV1_DD_RPwaveExists (nominal)], 97: [97 - chV1_RTwaveExists (nominal)], 98: [98 - chV1_DD_RTwaveExists (nominal)], 99: [99 - chV2_Qwave (numeric)], 100: [100 - chV2_Rwave (numeric)], 101: [101 - chV2_Swave (numeric)], 102: [102 - chV2_RPwave (numeric)], 103: [103 - chV2_SPwave (numeric)], 104: [104 - chV2_intrinsicReflecttions (numeric)], 105: [105 - chV2_RRwaveExists (nominal)], 106: [106 - chV2_DD_RRwaveExists (nominal)], 107: [107 - chV2_RPwaveExists (nominal)], 108: [108 - chV2_DD_RPwaveExists (nominal)], 109: [109 - chV2_RTwaveExists (nominal)], 110: [110 - chV2_DD_RTwaveExists (nominal)], 111: [111 - chV3_Qwave (numeric)], 112: [112 - chV3_Rwave (numeric)], 113: [113 - chV3_Swave (numeric)], 114: [114 - chV3_RPwave (numeric)], 115: [115 - chV3_SPwave (numeric)], 116: [116 - chV3_intrinsicReflecttions (numeric)], 117: [117 - chV3_RRwaveExists (nominal)], 118: [118 - chV3_DD_RRwaveExists (nominal)], 119: [119 - chV3_RPwaveExists (nominal)], 120: [120 - chV3_DD_RPwaveExists (nominal)], 121: [121 - chV3_RTwaveExists (nominal)], 122: [122 - chV3_DD_RTwaveExists (nominal)], 123: [123 - chV4_Qwave (numeric)], 124: [124 - chV4_Rwave (numeric)], 125: [125 - chV4_Swave (numeric)], 126: [126 - chV4_RPwave (numeric)], 127: [127 - chV4_SPwave (numeric)], 128: [128 - chV4_intrinsicReflecttions (numeric)], 129: [129 - chV4_RRwaveExists (nominal)], 130: [130 - chV4_DD_RRwaveExists (nominal)], 131: [131 - chV4_RPwaveExists (nominal)], 132: [132 - chV4_DD_RPwaveExists (nominal)], 133: [133 - chV4_RTwaveExists (nominal)], 134: [134 - chV4_DD_RTwaveExists (nominal)], 135: [135 - chV5_Qwave (numeric)], 136: [136 - chV5_Rwave (numeric)], 137: [137 - chV5_Swave (numeric)], 138: [138 - chV5_RPwave (numeric)], 139: [139 - chV5_SPwave (numeric)], 140: [140 - chV5_intrinsicReflecttions (numeric)], 141: [141 - chV5_RRwaveExists (nominal)], 142: [142 - chV5_DD_RRwaveExists (nominal)], 143: [143 - chV5_RPwaveExists (nominal)], 144: [144 - chV5_DD_RPwaveExists (nominal)], 145: [145 - chV5_RTwaveExists (nominal)], 146: [146 - chV5_DD_RTwaveExists (nominal)], 147: [147 - chV6_Qwave (numeric)], 148: [148 - chV6_Rwave (numeric)], 149: [149 - chV6_Swave (numeric)], 150: [150 - chV6_RPwave (numeric)], 151: [151 - chV6_SPwave (numeric)], 152: [152 - chV6_intrinsicReflecttions (numeric)], 153: [153 - chV6_RRwaveExists (nominal)], 154: [154 - chV6_DD_RRwaveExists (nominal)], 155: [155 - chV6_RPwaveExists (nominal)], 156: [156 - chV6_DD_RPwaveExists (nominal)], 157: [157 - chV6_RTwaveExists (nominal)], 158: [158 - chV6_DD_RTwaveExists (nominal)], 159: [159 - chDI_JJwaveAmp (numeric)], 160: [160 - chDI_QwaveAmp (numeric)], 161: [161 - chDI_RwaveAmp (numeric)], 162: [162 - chDI_SwaveAmp (numeric)], 163: [163 - chDI_RPwaveAmp (numeric)], 164: [164 - chDI_SPwaveAmp (numeric)], 165: [165 - chDI_PwaveAmp (numeric)], 166: [166 - chDI_TwaveAmp (numeric)], 167: [167 - chDI_QRSA (numeric)], 168: [168 - chDI_QRSTA (numeric)], 169: [169 - chDII_JJwaveAmp (numeric)], 170: [170 - chDII_QwaveAmp (numeric)], 171: [171 - chDII_RwaveAmp (numeric)], 172: [172 - chDII_SwaveAmp (numeric)], 173: [173 - chDII_RPwaveAmp (numeric)], 174: [174 - chDII_SPwaveAmp (numeric)], 175: [175 - chDII_PwaveAmp (numeric)], 176: [176 - chDII_TwaveAmp (numeric)], 177: [177 - chDII_QRSA (numeric)], 178: [178 - chDII_QRSTA (numeric)], 179: [179 - chDIII_JJwaveAmp (numeric)], 180: [180 - chDIII_QwaveAmp (numeric)], 181: [181 - chDIII_RwaveAmp (numeric)], 182: [182 - chDIII_SwaveAmp (numeric)], 183: [183 - chDIII_RPwaveAmp (numeric)], 184: [184 - chDIII_SPwaveAmp (numeric)], 185: [185 - chDIII_PwaveAmp (numeric)], 186: [186 - chDIII_TwaveAmp (numeric)], 187: [187 - chDIII_QRSA (numeric)], 188: [188 - chDIII_QRSTA (numeric)], 189: [189 - chAVR_JJwaveAmp (numeric)], 190: [190 - chAVR_QwaveAmp (numeric)], 191: [191 - chAVR_RwaveAmp (numeric)], 192: [192 - chAVR_SwaveAmp (numeric)], 193: [193 - chAVR_RPwaveAmp (numeric)], 194: [194 - chAVR_SPwaveAmp (numeric)], 195: [195 - chAVR_PwaveAmp (numeric)], 196: [196 - chAVR_TwaveAmp (numeric)], 197: [197 - chAVR_QRSA (numeric)], 198: [198 - chAVR_QRSTA (numeric)], 199: [199 - chAVL_JJwaveAmp (numeric)], 200: [200 - chAVL_QwaveAmp (numeric)], 201: [201 - chAVL_RwaveAmp (numeric)], 202: [202 - chAVL_SwaveAmp (numeric)], 203: [203 - chAVL_RPwaveAmp (numeric)], 204: [204 - chAVL_SPwaveAmp (numeric)], 205: [205 - chAVL_PwaveAmp (numeric)], 206: [206 - chAVL_TwaveAmp (numeric)], 207: [207 - chAVL_QRSA (numeric)], 208: [208 - chAVL_QRSTA (numeric)], 209: [209 - chAVF_JJwaveAmp (numeric)], 210: [210 - chAVF_QwaveAmp (numeric)], 211: [211 - chAVF_RwaveAmp (numeric)], 212: [212 - chAVF_SwaveAmp (numeric)], 213: [213 - chAVF_RPwaveAmp (numeric)], 214: [214 - chAVF_SPwaveAmp (numeric)], 215: [215 - chAVF_PwaveAmp (numeric)], 216: [216 - chAVF_TwaveAmp (numeric)], 217: [217 - chAVF_QRSA (numeric)], 218: [218 - chAVF_QRSTA (numeric)], 219: [219 - chV1_JJwaveAmp (numeric)], 220: [220 - chV1_QwaveAmp (numeric)], 221: [221 - chV1_RwaveAmp (numeric)], 222: [222 - chV1_SwaveAmp (numeric)], 223: [223 - chV1_RPwaveAmp (numeric)], 224: [224 - chV1_SPwaveAmp (numeric)], 225: [225 - chV1_PwaveAmp (numeric)], 226: [226 - chV1_TwaveAmp (numeric)], 227: [227 - chV1_QRSA (numeric)], 228: [228 - chV1_QRSTA (numeric)], 229: [229 - chV2_JJwaveAmp (numeric)], 230: [230 - chV2_QwaveAmp (numeric)], 231: [231 - chV2_RwaveAmp (numeric)], 232: [232 - chV2_SwaveAmp (numeric)], 233: [233 - chV2_RPwaveAmp (numeric)], 234: [234 - chV2_SPwaveAmp (numeric)], 235: [235 - chV2_PwaveAmp (numeric)], 236: [236 - chV2_TwaveAmp (numeric)], 237: [237 - chV2_QRSA (numeric)], 238: [238 - chV2_QRSTA (numeric)], 239: [239 - chV3_JJwaveAmp (numeric)], 240: [240 - chV3_QwaveAmp (numeric)], 241: [241 - chV3_RwaveAmp (numeric)], 242: [242 - chV3_SwaveAmp (numeric)], 243: [243 - chV3_RPwaveAmp (numeric)], 244: [244 - chV3_SPwaveAmp (numeric)], 245: [245 - chV3_PwaveAmp (numeric)], 246: [246 - chV3_TwaveAmp (numeric)], 247: [247 - chV3_QRSA (numeric)], 248: [248 - chV3_QRSTA (numeric)], 249: [249 - chV4_JJwaveAmp (numeric)], 250: [250 - chV4_QwaveAmp (numeric)], 251: [251 - chV4_RwaveAmp (numeric)], 252: [252 - chV4_SwaveAmp (numeric)], 253: [253 - chV4_RPwaveAmp (numeric)], 254: [254 - chV4_SPwaveAmp (numeric)], 255: [255 - chV4_PwaveAmp (numeric)], 256: [256 - chV4_TwaveAmp (numeric)], 257: [257 - chV4_QRSA (numeric)], 258: [258 - chV4_QRSTA (numeric)], 259: [259 - chV5_JJwaveAmp (numeric)], 260: [260 - chV5_QwaveAmp (numeric)], 261: [261 - chV5_RwaveAmp (numeric)], 262: [262 - chV5_SwaveAmp (numeric)], 263: [263 - chV5_RPwaveAmp (numeric)], 264: [264 - chV5_SPwaveAmp (numeric)], 265: [265 - chV5_PwaveAmp (numeric)], 266: [266 - chV5_TwaveAmp (numeric)], 267: [267 - chV5_QRSA (numeric)], 268: [268 - chV5_QRSTA (numeric)], 269: [269 - chV6_JJwaveAmp (numeric)], 270: [270 - chV6_QwaveAmp (numeric)], 271: [271 - chV6_RwaveAmp (numeric)], 272: [272 - chV6_SwaveAmp (numeric)], 273: [273 - chV6_RPwaveAmp (numeric)], 274: [274 - chV6_SPwaveAmp (numeric)], 275: [275 - chV6_PwaveAmp (numeric)], 276: [276 - chV6_TwaveAmp (numeric)], 277: [277 - chV6_QRSA (numeric)], 278: [278 - chV6_QRSTA (numeric)], 279: [279 - class (nominal)]}\n","----------------------------------------\n","Rótulo padrão do conjunto de dados: class\n"]}]}]}